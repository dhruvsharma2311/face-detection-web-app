{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CY7ta3be2qQP",
        "outputId": "4bd84386-17db-4a85-e161-b4606fc3770d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: onnxruntime in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.21.1)\n",
            "Requirement already satisfied: coloredlogs in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime) (1.26.4)\n",
            "Requirement already satisfied: packaging in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime) (24.0)\n",
            "Requirement already satisfied: protobuf in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime) (1.14.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: pyreadline3 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime) (3.5.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting insightface\n",
            "  Using cached insightface-0.7.3.tar.gz (439 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Requirement already satisfied: numpy in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from insightface) (1.26.4)\n",
            "Collecting onnx (from insightface)\n",
            "  Using cached onnx-1.17.0-cp310-cp310-win_amd64.whl.metadata (16 kB)\n",
            "Collecting tqdm (from insightface)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting requests (from insightface)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from insightface) (3.8.4)\n",
            "Requirement already satisfied: Pillow in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from insightface) (10.0.0)\n",
            "Requirement already satisfied: scipy in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from insightface) (1.13.0)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from insightface) (1.6.1)\n",
            "Collecting scikit-image (from insightface)\n",
            "  Using cached scikit_image-0.25.2-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
            "Collecting easydict (from insightface)\n",
            "  Using cached easydict-1.13-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting cython (from insightface)\n",
            "  Using cached Cython-3.0.12-cp310-cp310-win_amd64.whl.metadata (3.6 kB)\n",
            "Collecting albumentations (from insightface)\n",
            "  Using cached albumentations-2.0.6-py3-none-any.whl.metadata (43 kB)\n",
            "Collecting prettytable (from insightface)\n",
            "  Using cached prettytable-3.16.0-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting PyYAML (from albumentations->insightface)\n",
            "  Using cached PyYAML-6.0.2-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
            "Collecting pydantic>=2.9.2 (from albumentations->insightface)\n",
            "  Using cached pydantic-2.11.4-py3-none-any.whl.metadata (66 kB)\n",
            "Collecting albucore==0.0.24 (from albumentations->insightface)\n",
            "  Using cached albucore-0.0.24-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting opencv-python-headless>=4.9.0.80 (from albumentations->insightface)\n",
            "  Using cached opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
            "Collecting stringzilla>=3.10.4 (from albucore==0.0.24->albumentations->insightface)\n",
            "  Using cached stringzilla-3.12.5-cp310-cp310-win_amd64.whl.metadata (81 kB)\n",
            "Collecting simsimd>=5.9.2 (from albucore==0.0.24->albumentations->insightface)\n",
            "  Using cached simsimd-6.2.1-cp310-cp310-win_amd64.whl.metadata (67 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->insightface) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->insightface) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->insightface) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->insightface) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->insightface) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->insightface) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->insightface) (2.9.0.post0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnx->insightface) (3.20.3)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\dhruv\\appdata\\roaming\\python\\python310\\site-packages (from prettytable->insightface) (0.2.13)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->insightface)\n",
            "  Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl.metadata (36 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->insightface)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->insightface)\n",
            "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->insightface)\n",
            "  Using cached certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: networkx>=3.0 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image->insightface) (3.4.2)\n",
            "Collecting Pillow (from insightface)\n",
            "  Using cached pillow-11.2.1-cp310-cp310-win_amd64.whl.metadata (9.1 kB)\n",
            "Collecting imageio!=2.35.0,>=2.33 (from scikit-image->insightface)\n",
            "  Using cached imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting tifffile>=2022.8.12 (from scikit-image->insightface)\n",
            "  Using cached tifffile-2025.3.30-py3-none-any.whl.metadata (32 kB)\n",
            "Collecting lazy-loader>=0.4 (from scikit-image->insightface)\n",
            "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->insightface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->insightface) (3.6.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->insightface) (0.4.6)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic>=2.9.2->albumentations->insightface)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic>=2.9.2->albumentations->insightface)\n",
            "  Using cached pydantic_core-2.33.2-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
            "Collecting typing-extensions>=4.12.2 (from pydantic>=2.9.2->albumentations->insightface)\n",
            "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic>=2.9.2->albumentations->insightface)\n",
            "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.16.0)\n",
            "Using cached albumentations-2.0.6-py3-none-any.whl (332 kB)\n",
            "Using cached albucore-0.0.24-py3-none-any.whl (15 kB)\n",
            "Using cached Cython-3.0.12-cp310-cp310-win_amd64.whl (2.8 MB)\n",
            "Using cached easydict-1.13-py3-none-any.whl (6.8 kB)\n",
            "Using cached onnx-1.17.0-cp310-cp310-win_amd64.whl (14.5 MB)\n",
            "Using cached prettytable-3.16.0-py3-none-any.whl (33 kB)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Using cached scikit_image-0.25.2-cp310-cp310-win_amd64.whl (12.8 MB)\n",
            "Using cached pillow-11.2.1-cp310-cp310-win_amd64.whl (2.7 MB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
            "Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl (102 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached imageio-2.37.0-py3-none-any.whl (315 kB)\n",
            "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
            "Using cached opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl (39.4 MB)\n",
            "Using cached pydantic-2.11.4-py3-none-any.whl (443 kB)\n",
            "Using cached pydantic_core-2.33.2-cp310-cp310-win_amd64.whl (2.0 MB)\n",
            "Using cached tifffile-2025.3.30-py3-none-any.whl (226 kB)\n",
            "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "Using cached PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Using cached simsimd-6.2.1-cp310-cp310-win_amd64.whl (86 kB)\n",
            "Using cached stringzilla-3.12.5-cp310-cp310-win_amd64.whl (80 kB)\n",
            "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: insightface\n",
            "  Building wheel for insightface (pyproject.toml): started\n",
            "  Building wheel for insightface (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for insightface: filename=insightface-0.7.3-cp310-cp310-win_amd64.whl size=872977 sha256=ef73229f20c3ae39b56b705da259578138b82e26bda5ab91ebfffe5e8494b93f\n",
            "  Stored in directory: c:\\users\\dhruv\\appdata\\local\\pip\\cache\\wheels\\e3\\d0\\80\\e3773fb8b6d1cca87ea1d33d9b1f20a223a6493c896da249b5\n",
            "Successfully built insightface\n",
            "Installing collected packages: stringzilla, simsimd, easydict, urllib3, typing-extensions, tqdm, tifffile, PyYAML, prettytable, Pillow, opencv-python-headless, onnx, lazy-loader, idna, cython, charset-normalizer, certifi, annotated-types, typing-inspection, requests, pydantic-core, imageio, albucore, scikit-image, pydantic, albumentations, insightface\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.11.0\n",
            "    Uninstalling typing_extensions-4.11.0:\n",
            "      Successfully uninstalled typing_extensions-4.11.0\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 10.0.0\n",
            "    Uninstalling Pillow-10.0.0:\n",
            "      Successfully uninstalled Pillow-10.0.0\n",
            "Successfully installed Pillow-11.2.1 PyYAML-6.0.2 albucore-0.0.24 albumentations-2.0.6 annotated-types-0.7.0 certifi-2025.4.26 charset-normalizer-3.4.1 cython-3.0.12 easydict-1.13 idna-3.10 imageio-2.37.0 insightface-0.7.3 lazy-loader-0.4 onnx-1.17.0 opencv-python-headless-4.11.0.86 prettytable-3.16.0 pydantic-2.11.4 pydantic-core-2.33.2 requests-2.32.3 scikit-image-0.25.2 simsimd-6.2.1 stringzilla-3.12.5 tifffile-2025.3.30 tqdm-4.67.1 typing-extensions-4.13.2 typing-inspection-0.4.0 urllib3-2.4.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opencv-python) (1.26.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.13.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.7.0)\n",
            "Requirement already satisfied: torchvision in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.22.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dhruv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install onnxruntime\n",
        "!pip install insightface\n",
        "!pip install opencv-python\n",
        "!pip install pandas\n",
        "!pip install scikit-learn\n",
        "!pip install torch torchvision\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from insightface.app import FaceAnalysis\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_o6y5Fot4Ia_",
        "outputId": "c3318e3b-c489-458f-e787-b54006bb2d13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "download_path: C:\\Users\\dhruv/.insightface\\models\\buffalo_l\n",
            "Downloading C:\\Users\\dhruv/.insightface\\models\\buffalo_l.zip from https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 281857/281857 [00:09<00:00, 29607.40KB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: C:\\Users\\dhruv/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: C:\\Users\\dhruv/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: C:\\Users\\dhruv/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: C:\\Users\\dhruv/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: C:\\Users\\dhruv/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (640, 640)\n",
            "✅ Model loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# Load InsightFace FaceAnalysis model\n",
        "def load_face_analyzer():\n",
        "    app = FaceAnalysis(name=\"buffalo_l\", providers=['CPUExecutionProvider'])\n",
        "    app.prepare(ctx_id=0, det_size=(640, 640))\n",
        "    return app\n",
        "\n",
        "# Initialize model\n",
        "face_app = load_face_analyzer()\n",
        "\n",
        "# face_app now holds the face detection and recognition engine, ready to be used to analyze images.\n",
        "\n",
        "print(\"✅ Model loaded successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "-aEv78925-xb",
        "outputId": "b85342dd-5952-4a85-f1b8-b54e61d9f183"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Dataset extracted!\n"
          ]
        }
      ],
      "source": [
        "# import zipfile\n",
        "# import os\n",
        "\n",
        "# # upload dataset to colab\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# # unzip the dataset\n",
        "# with zipfile.ZipFile(\"dataset.zip\", 'r') as zip_ref:\n",
        "#     zip_ref.extractall(\".\")\n",
        "\n",
        "# print(\"✅ Dataset extracted!\")\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to your local zip file\n",
        "zip_path = \"dataset.zip\"\n",
        "extract_to = \".\"\n",
        "\n",
        "# Unzip only if folder doesn't already exist\n",
        "if not os.path.exists(\"dataset\"):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(\"✅ Dataset extracted!\")\n",
        "else:\n",
        "    print(\"ℹ️ Dataset already extracted.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOvd2WvI6oKH",
        "outputId": "938cc69a-6378-4d7e-ac6e-f6e08f2fe154"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\dhruv\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\insightface\\utils\\transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Database built with 5 people.\n"
          ]
        }
      ],
      "source": [
        "# Function to build and empty dictionary face_db to store:\n",
        "#Key: Folder name (e.g., 'ID001_John')\n",
        "#Value: Average face embedding (512-dimensional NumPy array)\n",
        "\n",
        "def build_database(dataset_path='dataset', database_file='face_database.pkl'):\n",
        "    face_db = {}\n",
        "\n",
        "    # Iterates through every subfolder name (i.e., person folders) in the dataset directory.\n",
        "    for person_folder in os.listdir(dataset_path):\n",
        "\n",
        "        # Constructs the full path to the person’s folder using os.path.join.\n",
        "        person_path = os.path.join(dataset_path, person_folder)\n",
        "        if os.path.isdir(person_path):  #Checks if the path is indeed a folder (not a file), to avoid errors.\n",
        "            embeddings = []\n",
        "\n",
        "            # Iterates through all image filenames inside that person’s folder.\n",
        "            for img_file in os.listdir(person_path):\n",
        "                img_path = os.path.join(person_path, img_file)\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is None:\n",
        "                    continue\n",
        "                faces = face_app.get(img)    # Runs face detection + embedding extraction on the image.\n",
        "                if faces:\n",
        "                    embeddings.append(faces[0].embedding)\n",
        "\n",
        "            # Stores this avg embedding in the face_db dictionary with key = folder name ('ID001_John')\n",
        "            if embeddings:\n",
        "                avg_embedding = np.mean(embeddings, axis=0)\n",
        "                face_db[person_folder] = avg_embedding\n",
        "\n",
        "    # Save database\n",
        "    with open('face_database.pkl', 'wb') as f:\n",
        "        pickle.dump(face_db, f)\n",
        "\n",
        "    print(f\"✅ Database built with {len(face_db)} people.\")\n",
        "\n",
        "# Build it\n",
        "build_database('dataset')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "YL1Wz2FsaPPp",
        "outputId": "59e1a3c4-0eec-49db-e763-7ecb12342b9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Created folder: dataset\\_\n",
            "\n",
            "📂 Please place the new person's image files in this folder:\n",
            "   --> dataset\\_\n",
            "❌ No images found in the folder.\n",
            "❌ No valid faces detected. Person not added.\n",
            "✅ face_database.pkl updated with the new person.\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Get ID and name\n",
        "new_id = input(\"Enter new person's ID: \").strip()\n",
        "new_name = input(\"Enter new person's Name: \").strip()\n",
        "folder_name = f\"{new_id}_{new_name}\"\n",
        "folder_path = os.path.join(\"dataset\", folder_name)\n",
        "\n",
        "# Step 2: Create directory for the new person\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "print(f\"✅ Created folder: {folder_path}\")\n",
        "\n",
        "# Step 3: Ask user to copy or specify image files\n",
        "print(\"\\n📂 Please place the new person's image files in this folder:\")\n",
        "print(f\"   --> {folder_path}\")\n",
        "input(\"🛑 Press Enter after you've added the image(s) and are ready to continue...\")\n",
        "\n",
        "# Step 4: Collect image paths\n",
        "image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path)\n",
        "               if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "if not image_paths:\n",
        "    print(\"❌ No images found in the folder.\")\n",
        "    exit()\n",
        "\n",
        "# Step 5: Load existing face database\n",
        "if os.path.exists('face_database.pkl'):\n",
        "    with open('face_database.pkl', 'rb') as f:\n",
        "        face_db = pickle.load(f)\n",
        "else:\n",
        "    face_db = {}\n",
        "\n",
        "# Step 6: Generate embeddings using face_app\n",
        "embeddings = []\n",
        "for img_path in image_paths:\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        print(f\"⚠️ Warning: Could not read image: {img_path}\")\n",
        "        continue\n",
        "    faces = face_app.get(img)\n",
        "    if faces:\n",
        "        embeddings.append(faces[0].embedding)\n",
        "    else:\n",
        "        print(f\"⚠️ No face detected in: {img_path}\")\n",
        "\n",
        "# Step 7: Add to database\n",
        "if embeddings:\n",
        "    avg_embedding = np.mean(embeddings, axis=0)\n",
        "    face_db[folder_name] = avg_embedding\n",
        "    print(f\"✅ Embedding added for {folder_name}\")\n",
        "else:\n",
        "    print(\"❌ No valid faces detected. Person not added.\")\n",
        "    exit()\n",
        "\n",
        "# Step 8: Save updated database\n",
        "with open('face_database.pkl', 'wb') as f:\n",
        "    pickle.dump(face_db, f)\n",
        "\n",
        "print(\"✅ face_database.pkl updated with the new person.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ssm9ei-27GPD",
        "outputId": "4e2058ae-2f25-49d9-80f3-9f028df3a233"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Detected 6 faces in group photo.\n"
          ]
        }
      ],
      "source": [
        "# Load group photo\n",
        "group_photo_path = '/content/grp_photo5.png'\n",
        "img = cv2.imread(group_photo_path)\n",
        "\n",
        "# Runs face detection + embedding extraction on the image.\n",
        "group_faces = face_app.get(img)\n",
        "\n",
        "print(f\"✅ Detected {len(group_faces)} faces in group photo.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7nLTBbtQ7iNo",
        "outputId": "9e4f0469-c354-4f56-8914-f0d39ff82ed4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Known IDs in database: ['ID003_Ramos', 'ID005_Kroos', 'ID001_Courtois', 'ID002_Ronaldo', 'ID004_Benzema', 'ID008_Bale']\n",
            "Detected faces in group photo: 6\n",
            "\n",
            "Face #1\n",
            "Best similarity score: 0.8646641969680786\n",
            "✅ Matched with: ID002_Ronaldo\n",
            "\n",
            "Face #2\n",
            "Best similarity score: 0.8066542148590088\n",
            "✅ Matched with: ID003_Ramos\n",
            "\n",
            "Face #3\n",
            "Best similarity score: 0.73204505443573\n",
            "✅ Matched with: ID008_Bale\n",
            "\n",
            "Face #4\n",
            "Best similarity score: 0.7400767207145691\n",
            "✅ Matched with: ID004_Benzema\n",
            "\n",
            "Face #5\n",
            "Best similarity score: 0.011730385944247246\n",
            "❌ Unknown face detected\n",
            "\n",
            "Face #6\n",
            "Best similarity score: 0.04959612712264061\n",
            "❌ Unknown face detected\n"
          ]
        }
      ],
      "source": [
        "# Load database\n",
        "# Loads the dictionary face_db containing:\n",
        "# Keys: person IDs like 'ID001_John'\n",
        "# Values: 512-dimensional face embeddings (NumPy arrays)\n",
        "\n",
        "with open('face_database.pkl', 'rb') as f:\n",
        "    face_db = pickle.load(f)\n",
        "\n",
        "known_ids = list(face_db.keys())  # list of folder names (IDs) from the database eg-['ID001_John']\n",
        "known_embeddings = np.stack(list(face_db.values()))\n",
        "\n",
        "# Match each detected face\n",
        "attendance_records = []   # will store tuples like ('ID001_John', 'Present')\n",
        "detected_ids = set()      # used to keep track of unique IDs already matched (helps avoid marking one person twice)\n",
        "\n",
        "threshold = 0.7  # Cosine similarity threshold\n",
        "\n",
        "print(f\"Known IDs in database: {known_ids}\")\n",
        "print(f\"Detected faces in group photo: {len(group_faces)}\")\n",
        "\n",
        "# Loops through each detected face (face) in the group image.\n",
        "for i, face in enumerate(group_faces):\n",
        "    embedding = face.embedding.reshape(1, -1)\n",
        "\n",
        "    # Computes cosine similarity btw the detected face embedding and all known embeddings.\n",
        "    similarities = cosine_similarity(embedding, known_embeddings)[0]\n",
        "\n",
        "    # Finds the index of the highest similarity score, and extracts that score.\n",
        "    best_match_idx = np.argmax(similarities)\n",
        "    best_score = similarities[best_match_idx]\n",
        "\n",
        "    print(f\"\\nFace #{i+1}\")\n",
        "    print(f\"Best similarity score: {best_score}\")\n",
        "\n",
        "    if best_score > threshold:\n",
        "        matched_id = known_ids[best_match_idx]\n",
        "        print(f\"✅ Matched with: {matched_id}\")\n",
        "        attendance_records.append((matched_id, \"Present\"))\n",
        "        detected_ids.add(matched_id)\n",
        "    else:\n",
        "        print(\"❌ Unknown face detected\")\n",
        "        attendance_records.append((\"Unknown\", \"Unknown\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6uHDRCXHy1X",
        "outputId": "4eb75bdb-ed01-4c1f-aaa2-c49ee5dcfcb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Attendance exported to attendance.csv successfully!\n"
          ]
        }
      ],
      "source": [
        "# Mark absentees\n",
        "for id_name in known_ids:\n",
        "    if id_name not in detected_ids:\n",
        "        attendance_records.append((id_name, \"Absent\"))\n",
        "\n",
        "# Export CSV\n",
        "df = pd.DataFrame(attendance_records, columns=[\"ID_Name\", \"Status\"])\n",
        "df[['ID', 'Name']] = df['ID_Name'].str.split('_', expand=True)\n",
        "df = df[['ID', 'Name', 'Status']]\n",
        "df.to_csv('attendance.csv', index=False)\n",
        "\n",
        "print(\"✅ Attendance exported to attendance.csv successfully!\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
